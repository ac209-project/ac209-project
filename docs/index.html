<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">

    <title>Spotify's Next Top Model</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/simple-sidebar.css" rel="stylesheet">

    <!-- Our styles -->
    <link href="css/style.css" rel="stylesheet">

</head>

<body>

<div id="wrapper">

    <!-- Sidebar -->
    <div id="sidebar-wrapper">
        <ul class="sidebar-nav">
            <li class="sidebar-brand">
                <a href="#">
                    Project Menu
                </a>
            </li>
            <li>
                <a href="#probstatement">Problem Statement</a>
            </li>
            <li>
                <a href="#data">Introduction & Data</a>
            </li>
            <li>
                <a href="#lit">Literature Review</a>
            </li>
            <li>
                <a href="#models">Modeling & Trajectory</a>
            </li>
            <li>
                <a href="#results">Results</a>
            </li>
            <li>
                <a href="#references">References</a>
            </li>
            <li>
                <a href="#contact">Contact</a>
            </li>
        </ul>
    </div>
    <!-- /#sidebar-wrapper -->

    <!-- Page Content -->
    <div id="page-content-wrapper">
        <div class="container-fluid">

            <div class="row">
                <div class="col-md-12">
                    <h1>Spotify's Next Top Model</h1>
                    <p>
                        Welcome to our Harvard University, Fall 2017 - Data Science I final project page. Please use the
                        menu button below to jump to your section of choice.<br><br>
                        <a href="#menu-toggle" class="btn btn-secondary" id="menu-toggle">Toggle Menu</a>
                    </p>
                </div>
            </div>
            <hr>


            <div id="probstatement" class="row section">
                <div class="col col-md-12"><h2>Problem Statement & Motivation</h2></div>
            </div>

            <div class="row">
                <div class="col col-md-12">
                    <p>
                        The purpose of this project is to use publicly available data through Spotify's
                        <a href="https://developer.spotify.com/web-api/" target="_blank">API</a>, the
                        <a href="https://spotipy.readthedocs.io/en/latest/" target="_blank">Spotipy</a> python library,
                        <a href="https://github.com/ac209-project/ac209-project/tree/master/w2v" target="_blank">word-to-vector
                            feature engineering</a>, and <a href="https://www.usmagazine.com/celebrities/a/">celebrity
                        information</a> to
                        predict the success of Spotify user playlists, and create a tool to build successful playlists
                        based on user specified features (genre, artist, etc.).
                    </p>
                    <p>
                        Throughout this project "playlist success" (our response variable) is defined as the number of
                        playlist followers. We have employed machine-learning regression techniques taught throughout
                        the semester as well as
                        <a href="https://en.wikipedia.org/wiki/Word2vec" target="_blank">Word2vec</a> modeling to
                        predict playlist
                        success.
                    </p>
                </div>
            </div>
            <hr>

            <div id="data" class="row">
                <div class="col col-md-12">
                    <h2>Introduction & Description of Data</h2>
                    <p>In this section we will give you some insights in to the data we collected, aggregated, and
                        combined, as well as the in-depth exploratory data analysis (EDA) performed to try and
                        illustrate relationships surrounding playlist success - specifically artist categorization,
                        artist and playlist genres, and playlist popularity as it relates to time.</p>
                </div>
            </div>

            <div class="row">
                <div class="col col-md-12">
                    <p><b>Baseline Data:</b><br>
                        Baseline data was collected primarily from the Spotify API. After
                        sourcing the Spotify users who “own” (the playlists are attached to their accounts) a large
                        number of playlists, the spotipy library was employed to collect user playlists, tracks, user
                        followers, and genre data from the API, each saved as JSON files. Genre information for
                        each playlist was harder to source and incorporate than one would think. It does not come
                        directly from each playlist, but rather from the artists of each track as a separate query. We
                        also collected celebrity names from <a href="https://www.usmagazine.com/celebrities/a/">US
                            Magazine</a>.
                    <p>
                        Before combining into one comprehensive DataFrame, the separate files have the following basic
                        form:
                    </p>
                    <table class="table table-striped table-project">
                        <thead>
                        <tr>
                            <th>Data File</th>
                            <th>Observations</th>
                            <th>Features</th>
                        </tr>
                        </thead>
                        <tbody>
                        <tr>
                            <td>Usernames</td>
                            <td>846</td>
                            <td>1</td>
                        </tr>
                        <tr>
                            <td>Celebrity Names</td>
                            <td>840</td>
                            <td>1</td>
                        </tr>
                        <tr>
                            <td>Genres</td>
                            <td>1343</td>
                            <td>5</td>
                        </tr>
                        <tr>
                            <td>Playlists</td>
                            <td>8183</td>
                            <td>7</td>
                        </tr>
                        <tr>
                            <td>Tracks</td>
                            <td>367911</td>
                            <td>8</td>
                        </tr>
                        </tbody>
                    </table>
                    <p>
                        The files were combined and manipulated into a single DataFrame via the playlist ID, username,
                        and artist name attributes. While cleaning, we decided to eliminate any playlist with fewer than
                        one follower (the owner).
                    </p>
                    <p>
                        We explore the data (and our engineered features) at both the track and the playlist level. As
                        you can see above, we have about 9.7 playlists per user when we include all users. When we
                        drop playlists with below 1 follower, we have about 4.4 playlists per user. Likewise, we start
                        with ~368k tracks and after we drop the playlists with fewer than 1 follower we only have ~211k
                        tracks remaining.
                    </p>
                    <p>
                        This is clearly a biased subsample of playlists in that we sourced users that own high numbers
                        of playlists and removed those playlists with only one follower, but the flipside is that the
                        vast majority of Spotify users are only making playlists for themselves (one user), or maybe
                        sharing them with just friends of close loved ones. A cross-section of those users would make
                        our already right-skewed (as seen below) data even more skewed.</p>
                    <p>
                        Click <a href="https://github.com/ac209-project/ac209-project/tree/master/getplaylist"
                                 target="_blank">here</a>
                        to explore our data collection techniques.
                    </p>
                </div>
            </div>
            <hr>
            <div class="row">
                <div class="col col-md-8">
                    <p><b>Playlist Followers - A first look at playlist success:</b><br>
                        Engineering features around artist and playlist data yielded interesting relationships. A
                        cursory measure of playlist success, our generalized project goal, is the number of followers
                        per playlist. The distribution of playlist followers shows a significant right-skew, with most
                        playlists having few followers and a few approaching the 1M mark. The log-transform of followers
                        illustrates a potentially more useful response variable (right).
                    </p>
                </div>
                <div class="col col-md-4">
                    <img src="img/eda1.png" align="center" class="img">
                </div>
            </div>
            <hr>
            <div class="row">
                <div class="col-md-12">
                    <p><b>Categorizing artists:</b><br>
                        We further aggregated the artists by splitting them up into five distinct categories using
                        combinations of their mean popularity (as determined by Spotify's popularity metric) and total
                        number of artist tracks as seen in the following table. These categories should be
                        self-descriptive, but the two plots below do a fantastic job of illustrating each in terms of
                        their thresholds and relationships. The artist popularity metric ties in with our expectations
                        because we see people like Post Malone, Camila Cabello, and Ed Sheeran in our superstar
                        category.
                    </p>
                </div>
            </div>
            <div class="row">
                <div class="col-md-4">
                    <table class="table table-project">
                        <thead>
                        <tr>
                            <th>Artist Category</th>
                            <th>Artist Mean Track Popularity</th>
                            <th>Artist Total Tracks</th>
                        </tr>
                        </thead>
                        <tbody class="bands">
                        <tr style="background-color: #0022f5">
                            <td>Superstar</td>
                            <td>>= 50</td>
                            <td>>= 10</td>
                        </tr>
                        <tr style="background-color: #ed3323">
                            <td>Star</td>
                            <td>>= 20 and < 50</td>
                            <td>>= 10</td>
                        </tr>
                        </tr>
                        <tr style="background-color: #357d22">
                            <td>One-hit-wonder</td>
                            <td>>= 40</td>
                            <td>< 10</td>
                        </tr>
                        <tr style="background-color: #761a7c">
                            <td>Garage Band</td>
                            <td>< 40</td>
                            <td>< 10</td>
                        </tr>
                        <tr style="background-color: #fffd54">
                            <td>Trash Factory</td>
                            <td>>= 0 and < 20</td>
                            <td>>= 10</td>
                        </tbody>
                    </table>
                </div>
                <div class="col-md-8">
                    <img src="img/eda2.png" align="center" class="img"/>
                </div>
            </div>
            <hr>
            <div class="row">
                <div class="col-md-12">
                    <p><b>Continuing Artist Analysis:</b><br>
                        Below you can see a illustrative distribution of these five artist categories grouped by
                        playlist as they relate to number of playlist followers and specific track popularity (as
                        determined by Spotify). We see
                        that, unsurprisingly, not only do most playlists incorporate popular artists (superstar: blue
                        and star:red), but a
                        lot of them have the superstar artists’ best songs (the mostly blue right side), as well as a
                        smattering of one-hit-wonders (green in the middle) and a dense area of moderately popular songs
                        throughout (between 30 and 70 popularity). This relationship and playlist architecture should
                        be intuitive. You can also note, interestingly, that only on-hit-wonders (green) get perfect
                        100s for
                        track popularity.
                    </p>
                </div>
            </div>
            <div class="row">
                <div class='col-md-7 mx-auto'><img src="img/eda3.png" class="img"/></div>
            </div>
            <hr>
            <div class="row">
                <div class="col-md-12">
                    <p>
                        <b>Playlists & Time:</b><br>
                        It appears that there may be a relationship between the number of tracks a playlist has and its
                        number of followers (top-left), as well as length of its description (top-right). We also
                        investigated the impact of playlist turnover rate, or relative age, days between the oldest and
                        newest track being added (bottom-left), as well as the age of the oldest song on playlist
                        follower count (bottom-right).
                    </p>
                </div>
            </div>
            <div class="row">
                <div class='col-md-10 mx-auto'><img src="img/eda4.png" class="img"/></div>
            </div>
            <hr>
            <div class="row">
                <div class="col-md-12">
                    <p><b>Track Popularity:</b><br>
                        We also took a closer look at other playlist metrics, specifically average playlist track
                        popularity versus the number of tracks in a playlist or the maximum playlist track popularity as
                        seen in the following two plots, respectively. Does it matter more to have a few really popular
                        songs, or just a lot of decent songs? From our graphs below we would say having a few good songs
                        is more important. The graph on the right below shows the average playlist track popularity and
                        the max track popularity colored by playlist followers. We can see the playlists with lots of
                        followers (dark blue) are much more consistently in the section with high max track popularity
                        regardless of their mean track popularity.</p>
                </div>
            </div>
            <div class="row">
                <div class="col-md-10 mx-auto"><img src="img/eda5.png" class="img"/></div>
            </div>
            <hr>
            <div class="row">
                <div class="col-md-12">
                    <p>
                        <b>Genres:</b><br>
                        If you were to ask anyone on the street how they would measure the success of any playlist, one
                        of their first responses would probably be "Depends on the genre." This is a natural
                        categorization we do with music on a daily basis. It is typically how we choose what we are
                        going to listen to when we go to the gym, start our daily commute, or go for a hike in the
                        woods, so of course the predominate genres that make up a playlist will have some impact on the
                        relative success of that playlist against all others, as well as those geared toward the same
                        genre.
                    </p>
                    <p>
                        In this section you will see four distinct looks at how genres, at the artist, playlist,
                        and track levels, impact playlist success.<br>

                        <b>Artist Genres - </b>The top-left barplot shows the median number of playlist followers, so as
                        to be less sensitive
                        to outliers.

                        The top-right barplot is based on mean artist popularity by genre. As you can
                        see, there are some specific genres at the top that we would usually associate with one artist
                        (canadian pop - Justin Bieber, detroit hip hop - Eminem). It is likely those artists are skewing
                        the distribution, since those are their respective genres. Sadly, we do not have enough members
                        of each genre to get a good view of the most popular genres by artist.<br>

                        <b>Playlist Genres - </b>The bottom-left barplot look at the most common genre by number of
                        playlist occurrences. Here we use the "mode genre" field. This field is made by looking at all
                        the genres that make up a playlist (on a track level) and choosing the most common (mode).<br>

                        <b>Track Genres - </b>The bottom-right barplot takes a look at some "genre-type"
                        information. We are specifically looking at any sub-genres that fall in a larger, more
                        general genre. For example, 'classic rock', 'heavy rock', and 'swedish electronic pop rock'
                        would all fall in our 'rock' genre-type. For each genre related to a song we have binary
                        variables to indicate whether that genre-type is present in the track. The genres in this plot
                        represent the 15 most common genres in our dataset [alternative, Christmas, country, dance,
                        deep, hip hop, house, indie, jazz, latin, metal, pop, rap, rock, soul].<br>

                        <br><b>Note:</b> We decided to use the top 15 genres since this corresponds to industry
                        standards for categorizing music. For example, iTunes "search-by-genre" has twenty-two and
                        <i>Billboard 200</i> uses ten.
                    </p>
                </div>
            </div>
            <div class="row">
                <div class="col-md-6 mx-auto"><img src="img/eda7.png" class="img"/></div>
                <div class="col-md-6 mx-auto"><img src="img/eda8.png" class="img"/></div>
            </div>
            <div class="row">
                <div class="col-md-6 mx-auto"><img src="img/eda9.png" class="img"/></div>
                <div class="col-md-6 mx-auto"><img src="img/eda10.png" class="img"/></div>
            </div>
            <hr>
            <div class="row">
                <div class="col-md-8">
                    <p>
                        <b>Celebrity Playlist Owners:</b><br>
                        Lastly, we explored whether the owner of the playlist is a known celebrity. The motivation for
                        this is that some of the most popular playlists we have seen have been from a celebrity's
                        official
                        Spotify account. We would like to be able to account for this bias.</p>
                    <p>
                        As you can see, there are not a huge numb
                    </p>
                </div>
                <div class="col-md-4 mx-auto"><img src="img/eda11.png" class="img"/></div>

            </div>
            <div class="row">
                <div class="col-md-12">
                    <p>Click <a href="https://github.com/ac209-project/ac209-project/tree/master/EDA" target="_blank">here</a>
                        for a closer look at our EDA techniques.</p>
                </div>
            </div>
            <hr>

            <div id="lit" class="row">
                <div class="col col-md-12"><h2>Literature Review & Related Work</h2></div>
            </div>

            <div class="row">
                <div class="col col-md-8">
                    <p>
                        A major contributing source for developing our 209-level feature using word-to-vec (w2v)
                        analysis of
                        playlist titles was <a
                            href="https://github.com/ac209-project/ac209-project/blob/master/w2v/word2vec_paper.pdf"
                            target="_blank">this paper</a> (Mikolov, Chen, Corrado, & Dean, 2013) entitled "Efficient
                        Estimation of Word Representations in Vector Space." The paper abstract follows:
                    </p>
                    <p style="text-align: justify; padding: 3%;"><i>We propose two novel model architectures for
                        computing continuous vector representations of words from very large data sets. The quality of
                        these representations is measured in a word similarity task, and the results are compared to the
                        previously best performing techniques based on different types of neural networks. We observe
                        large improvements in accuracy at much lower computational cost, i.e. it takes less than a day
                        to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that
                        these vectors provide state-of-the-art performance on our test set for measuring syntactic and
                        semantic word similarities.</i>
                    </p>
                </div>
                <div class="col col-md-4">
                    <img src="img/w2v1.png" align="center" class="img"/>
                    <p class="caption">A preview of our w2v feature generation</p>
                </div>
            </div>
            <hr>


            <div id="models" class="row">
                <div class="col col-md-12"><h2>Modeling Approach & Project Trajectory</h2></div>
            </div>

            <div class="row">
                <div class="col col-md-12">
                    <p><b>Baseline Modeling:</b><br>
                        As we move into modeling and attempting to predict playlist success based on number of
                        followers, we again use the playlists (and related tracks) that have at least one follower. The
                        rational being that we do not want to use data that could skew the popularity metrics for tracks
                        if it is unikely that those users have any followers that could potentially follow their
                        playlist. Essentially, we do not think those users have enough presence on Spotify for the
                        number of followers to be a meaningful feedback metric for playlist success. This left us with
                        a DataFrame consisting of 210,798 observations (tracks) across 49 measures, but since we are
                        predicting playlist followers and do not have time or experience to implement a full
                        hierarchical model, we aggregate our track, artist, and user information up to the playlist
                        level.
                    </p>
                    <p>
                        <b>Imputation:</b><br>
                        We also changed our datetime format columns to just include the year, and we median impute for
                        the (few) missing values in other columns.
                    </p>
                    <p>
                        <b>One-hot-encoding and train/test split:</b><br>
                        Since we have a number of categorical measures, one-hot-encoding was applied and resulted in a
                        DataFrame with ~3500 playlists across 480 columns.
                    </p>
                    <p>
                        We split the the the data with 75% in the training set and 25% in test, standardized the
                        numerical columns, then took an iterative
                        approach to modeling, using 5-fold cross-validation throughout, and moved through eight
                        different regression techniques: ridge, lasso, elastic net, k-NN, random forest,
                        AdaBoost, XGBoost, and SVM.
                    </p>
                </div>
            </div>
            <hr>
            <div class="row">
                <div class="col col-md-12">
                    <p><b>Word2vec on Playlist Names:</b><br>
                        In order to go beyond the scope of 109A and incorporate a method not discussed in class, we
                        decided to apply a word-to-vec (w2v) transform to as many applicable words as there are in
                        the set of playlist names. The core intuition being that the playlist name is what represents
                        the playlist to the outside world. A bad playlist name can keep people from following or
                        listening to it, even if the content is great, while a good playlist name can draw users. The
                        playlist name also, hopefully, categorizes the playlist in a meaningful way we can used. This
                        categorization could be by genre, mood, activity or any other type of category the playlist
                        creator thought was useful.
                    </p>
                    <p>
                        Click <a href="https://github.com/ac209-project/ac209-project/tree/master/w2v" target="_blank">here</a>
                        to
                        explore the w2v model training and implentation specific to our project.
                    </p>
                    <p>
                        <b>W2V Techique:</b><br>
                        By using word-to-vec we seek to cluster the playlist names into meaningful categories based on
                        the normalized sum of the vectors of known words in the playlist. This will aggregate the vector
                        information from each word in the playlist description, with all unknown words set to the zero
                        vector. We normalize the vectors in one feature (we have a normalizzed and a not normalized
                        version of this feature) once we aggregate them to stop playlists with just many words from
                        being higher in magnitude than playlists with just a few words.
                    </p>
                    <p>
                        <b>W2V Difficulties:</b><br>
                        Ultimately, there will be some difficulties with misspellings, different languages, and internet
                        slang (or emojis), and we will doubtless lose information in this quick application of w2v, but
                        we think the output will still be a meaningful feature in our final model. We have corrected for
                        many of these as was quickly possible with some simple NLTK and regex tools.
                    </p>
                    <p>
                        <b>W2V Model:</b><br>
                        Our w2v model was trained with the Text8 wikipedia corpus. This corpus seemed to be the
                        most applicable one that was both a reasonable size to download to a personal computer and took
                        a reasonable amount of time to train. After training the model, the "sentences" formed
                        by the playlist names were added to the vocabulary of the model. Without proper
                        context the model will not denote a vector transform for a word, so there are still several
                        words that do not have a related vector representation.
                    </p>
                    <p>
                        About 84% of the playlist names have at least one meaningful word (not a stop word by NLTK
                        standards) that has a vector representation in our model. This number could doubtless be
                        improved with a music specific or more casual internet chat area like Twitter or Reddit dataset
                        as opposed to the more formal Wikipedia dataset, but there is only so much time to make our
                        features.
                    </p>
                    <p>
                        The below plot shows different word locations in a sample of our TSNE plot. There is some
                        structure to the word placement. Toward the bottom, there are several spanish
                        words and related genres (like salsa and classicos). We can also see some other consistencies,
                        like "kendrick" and "hip hop" are together in one group, and "party", "club" and "pill" are all
                        together in another group. The w2v transform is definitely noisy in this case though. We
                        think this is due to the smaller training set, and the makeup of the training set. The training
                        set is made up of wikipedia documents which, though they contain a lot of words, probably do not
                        have a lot of the same contexts or slang that we will see here. If we could train with a corpus
                        from Twitter or Reddit we might have better context for the slang and pithy statements we often
                        see in playlist names.
                    </p>
                    <div><img src="img/word_groupings.png" class="img"></div>
                </div>
            </div>
            <hr>
            <div class="row">
                <div class="col-md-6">
                    <p><b>Modeling without the w2v feature:</b><br>
                        We first used some basic regression models (and Random Forest) to see how they compare to the
                        models with the w2v feature.
                    </p>
                    <p>
                        Note: We did not include Linear Regression for two reasons:
                    <ol>
                        <li>We cross validate with Ridge and Lasso over very small values for our regularization term.
                        </li>
                        <li>We looked at unregularized linear regression; it was bad and not worth the time to run it.
                        </li>
                    </ol>
                    </p>
                </div>
                <div class="col-md-6">
                    <table class="table table-striped table-project">
                        <thead>
                        <tr>
                            <th>Model</th>
                            <th>Train Score</th>
                            <th>Test Score</th>
                        </tr>
                        </thead>
                        <tbody>
                        <tr>
                            <td>Ridge Regression</td>
                            <td>0.084026380104</td>
                            <td>0.0411555898746</td>
                        </tr>
                        <tr>
                            <td>Elastic Net Regression</td>
                            <td>0.0856918846622</td>
                            <td>0.0408969940616</td>
                        </tr>
                        <tr>
                            <td>Random Forest Regression</td>
                            <td>0.872547373809</td>
                            <td>0.136527177719</td>
                        </tr>
                        </tbody>
                    </table>
                </div>
            </div>
            <hr>
            <div class="row">
                <div class="col-md-6">
                    <p>
                        <b>Full Model Selection without w2v:</b><br>
                        We next iterated over several regressor models (with each parameter set optimized by 5-fold
                        cross-validation) to determine which performs best with this data both without the w2v
                        feature included. Find the results to the right.

                    <p>
                        We can see in these results that the best performing model on a cross-validated training set is
                        our random forest with 300 estimators.
                    </p>
                </div>
                <div class="col-md-6">
                    <table class="table table-striped table-project">
                        <thead>
                        <th>Model</th>
                        <th>Cross-validated validation<br>set R^2 mean & std<br>(5-folds)</th>
                        <th>Train Score</th>
                        <th>Test Score</th>
                        </thead>
                        <tbody>
                        <tr>
                            <td>Ridge Regression</td>
                            <td>-0.030256576859918376, 0.11125313901459834</td>
                            <td>0.0853779911556</td>
                            <td>0.0413614492559</td>
                        </tr>
                        <tr>
                            <td>Lasso Regression</td>
                            <td>-0.030256576859918376, 0.11125313901459834</td>
                            <td>0.0853779911556</td>
                            <td>0.0413614492559</td>
                        </tr>
                        <tr>
                            <td>Elastic Net Regression</td>
                            <td>-0.0028011693799219937, 0.06249175213203975</td>
                            <td>0.0884215423941</td>
                            <td>0.0410473844718</td>
                        </tr>
                        <tr>
                            <td>k-NN Regression</td>
                            <td>0.013480236420100952, 0.014509798407915084</td>
                            <td>0.0923044971552</td>
                            <td>0.0447576215128</td>
                        </tr>
                        <tr>
                            <td>Random Forest Regression</td>
                            <td>0.06498151001454726, 0.03988285917502669</td>
                            <td>0.878798558284</td>
                            <td>0.102835631709</td>
                        </tr>
                        <tr>
                            <td>AdaBoost Regression</td>
                            <td>-0.06615510226947337, 0.14867997551870718</td>
                            <td>0.471762846853</td>
                            <td>0.0671178069851</td>
                        </tr>
                        <tr>
                            <td>XGBoost Regression</td>
                            <td>-0.06309052342991424, 0.25255449612691144</td>
                            <td>0.471512394636</td>
                            <td>0.110631159802</td>
                        </tr>
                        <tr>
                            <td>SVM Regression</td>
                            <td>0.050170049519681514, 0.014360689088760155</td>
                            <td>0.161309635032</td>
                            <td>0.0632341098191</td>
                        </tr>
                        </tbody>
                    </table>
                </div>
            </div>
            <hr>
            <div class="row">
                <div class="col-md-12">
                    <p>
                        <b>Feature Selection:</b><br>
                        Before moving on to the results and playlist generation, let's take a quick look at feature
                        selection.
                    </p>
                    <p>
                        We can see above that the best performing model on a cross-validated training set is our random
                        forest with 300 estimators. We will use that as our baseline model - but we note that some
                        over-fitting occurs on the training set. We believe this is due to the high number of features
                        (some of which are codependent). So next, we try to reduce the feature set overall and see if
                        this leads to an increase in model performance.
                    </p>
                    <p>
                        The 30 most common features below are as expected - for example:
                    <ul>
                        <li>The followers of the playlist owner are highly predictive of playlist followers.</li>
                        <li>Having a playlist description makes followers more likely to follow.</li>
                        <li>Having a playlist description makes followers more likely to follow.</li>
                    </ul>
                    One hit wonders and superstars are the most important class of bands in a playlist.
                    Next, we try fitting all of our models again on the first 50 important features to see if
                    the model performs better on the significantly reduced feature set.
                    </p>
                    <p>
                        We can see below that the model performance on a cross-validated training set is generally worse
                        with the reduced feature set. So we will keep our baseline model and our original random forest
                        regressor when we add in the w2v feature.
                    </p>
                </div>
            </div>
            <div class="row">
                <div class="col-md-6">
                    <img src="img/features.png" class="img"/>
                </div>
                <div class="col-md-6">
                    <table class="table table-striped table-project">
                        <thead>
                        <th>Model</th>
                        <th>Cross-validated validation<br>set R^2 mean & std<br>(5-folds)</th>
                        <th>Train Score</th>
                        <th>Test Score</th>
                        </thead>
                        <tbody>
                        <tr>
                            <td>Ridge Regression</td>
                            <td>-0.0012099350604610388, 0.06014401823558278</td>
                            <td>0.0506409957292</td>
                            <td>0.034960605146</td>
                        </tr>
                        <tr>
                            <td>Lasso Regression</td>
                            <td>-0.031179089608199113, 0.11043536489467987</td>
                            <td>0.0835771438137</td>
                            <td>0.040393327611</td>
                        </tr>
                        <tr>
                            <td>Elastic Net Regression</td>
                            <td>-0.0028709466278603233, 0.06259040628484479</td>
                            <td>0.0742195304118</td>
                            <td>0.0420117696879</td>
                        </tr>
                        <tr>
                            <td>k-NN Regression</td>
                            <td>0.02365696902444836, 0.005290415228039509</td>
                            <td>0.0938927608193</td>
                            <td>0.0471011530949</td>
                        </tr>
                        <tr>
                            <td>Random Forest Regression</td>
                            <td>-0.012824365374335844, 0.17363765832838546</td>
                            <td>0.874413756852</td>
                            <td>0.108460311935</td>
                        </tr>
                        <tr>
                            <td>AdaBoost Regression</td>
                            <td>0.06851789843488665, 0.01991264170112891</td>
                            <td>0.815443417418</td>
                            <td>0.104618730911</td>
                        </tr>
                        <tr>
                            <td>XGBoost Regression</td>
                            <td>-0.06831414541031067, 0.24532113197831398</td>
                            <td>0.460142391737</td>
                            <td>0.123005276447</td>
                        </tr>
                        <tr>
                            <td>SVM Regression</td>
                            <td>0.044348184474051755, 0.03186671954730048</td>
                            <td>0.0870515728538</td>
                            <td>0.0503707715865</td>
                        </tr>
                        </tbody>
                    </table>
                </div>
            </div>
            <hr>
            <div class="row">
                <div class="col-md-6">
                    <p>
                        <b>Adding the 209 W2V Feature:</b><br>
                        The additional clustering from our w2v feature does not add
                        much to the model as a whole. This is likely for two reasons:
                    <ol>
                        <li>The w2v model could just be too noisy to actually add value to the model.</li>
                        <li>The playlist name might not be that important in general when you have information about the
                            number of followers of the user who "owns" the playlist, or some other confounding variable.
                        </li>
                    </ol>
                    Essentially, any influence from the name of the playlist may be close to conditionally independent
                    of the response given one (or a few) of the other variables. For either of these two reasons, the
                    209 w2v feature does not increase our model score. To test this hypothesis, we look at a quick
                    difference in the straightforward regression models and take the average of the improvement on
                    test accuracy with the feature vs without.
                    </p>
                    <p>
                        As seen to the right, the average improvement in score for each model with the w2v feature is
                        <b>2.36%</b>.
                    </p>
                </div>
                <div class="col-md-6">
                    <table class="table table-striped table-project">
                        <thead>
                        <th>Model</th>
                        <th>Train Score<br>with W2V</th>
                        <th>Train Score<br>without W2V</th>
                        <th>Test Score<br>with W2V</th>
                        <th>Test Score<br>without W2V</th>
                        </thead>
                        <tbody>
                        <tr>
                            <td>Ridge Regression</td>
                            <td>0.0812653316532</td>
                            <td>0.0797564462589</td>
                            <td>0.0392014393826</td>
                            <td>0.038960622454</td>
                        </tr>
                        <tr>
                            <td>Lasso Regression</td>
                            <td>0.0812653316532</td>
                            <td>0.0797564462589</td>
                            <td>0.0392014393826</td>
                            <td>0.038960622454</td>
                        </tr>
                        <tr>
                            <td>Elastic Net Regression</td>
                            <td>0.0728789565471</td>
                            <td>0.0810526332472</td>
                            <td>0.0412664603581</td>
                            <td>0.0389881477994</td>
                        </tr>
                        </tbody>
                    </table>
                </div>
            </div>
            <hr>
            <div class="row">
                <div class="col-md-7">
                    <p>
                        <b>Generating Playlists:</b><br>
                        Aside from modeling playlist success we also developed a model to generate a of a user-defined
                        length and user-specified genre within the top 15 genres: alternative, christmas, country,
                        dance, deep, hip hop, metal, house, indie, jazz, latin, pop, rap, rock, and soul.
                    </p>
                    <p>
                        The model works by using our predictive model to predict a score for a playlist, and then
                        joining this with the unique track playlist combos. Then we aggregate up to individual track
                        id's, summing up the playlist scores. Once we are here, we have the data we need.
                    </p>
                    <p>
                        Now, when we run the generative model, we get just tracks that are realted to the specified
                        genre, and treat that as a distribution to sample from. We then normalize the predicted "scores"
                        from our model and scale them so they are valid probabilities.
                    </p>
                    <p>
                        Finally we sample from the distribution of the songs in our genre with the
                        associated probabilities given to them by the model. A sample "Latin" 20-song playlist is found
                        to the right.
                    </p>
                    <p>
                        Note: Each song can possibly be found in multiple genres.
                    </p>
                </div>
                <div class="col-md-5">
                    <img src="img/playlist.png" class="img">
                    <div class="caption">Sample 20 song "Latin" playlist</div>
                </div>

            </div>
            <hr>


            <div id="results" class="row">
                <div class="col col-md-12"><h2>Results, Conclusions, & Future Work</h2></div>
            </div>
            <div class="row">
                <div class="col col-md-12">
                    <p><b>Results:</b><br>
                        Overall the best perfoming models for predicting Spotify playlist success are random forest and
                        XGBoost. When incorporating our 209-level w2v feature we see the average test score improve by
                        2.36%.
                    </p>
                    <p>
                        <b>Conclusions:</b><br>
                        We cannot say for sure that the genre variables confound the feature we made for with w2v,
                        but there is improvement with the feature versus without it, where there was previously none. In
                        addition, these features are the most intuitive to remove to check for improvement,
                        because they are related to the distribution of genres (i.e. the type of music in a playlist),
                        which is what our hypothesis about the playlist names was based on. We said a playlist's name
                        would be a good proxy for the contents, and our w2v feature shows promise that this hypothesis
                        could be true.
                    </p>
                    <p>
                        We also made a novel generative model to produce playlist with specific user-specified genres
                        that could have pratical value if adapted into a web or mobile application.
                    </p>
                    <p>
                        <b>Future Work:</b><br>
                        As noted in the w2v section, about 84% of the playlist names have at least one meaningful word
                        (not a stop word by NLTK standards) that has a vector representation in our model. This number
                        could doubtless be improved with a music specific or more casual internet chat area like Twitter
                        or Reddit dataset as opposed to the more formal Wikipedia dataset.
                    </p>
                    <p>
                        The generative model for playlist generation works great in notebook form. If given more time,
                        and requisite expertise, another feature of this project we would have liked to incorporate is a
                        kind of "webapp" where the reader could choose one of our predefined genres from a dropdown menu
                        to generate a playlist. Again as it stands, using the final project notebook works quite well.
                    </p>
                    <p style="font-style: italic">
                        Show and interpret your results. Summarize your
                        results, the strengths and short-comings of your results, and speculate on how you might
                        address these short-comings if given more time.
                    </p>
                </div>
            </div>
            <hr>

            <div id="references" class="row">
                <div class="col col-md-12"><h2>References</h2></div>
            </div>
            <div class="row">
                <div class="col col-md-12">
                    <ul>
                        <li><a href="https://developer.spotify.com/web-api/" target="_blank">Spotify Web API</a></li>
                        <li><a href="https://spotipy.readthedocs.io/en/latest/" target="_blank">Spotipy</a> python
                            library.
                        </li>
                        <li><a href="https://labrosa.ee.columbia.edu/millionsong/" target="_blank">Million Song
                            Dataset</a></li>
                        <li>
                            "Efficient Estimation of Word Representations in Vector Space." <a
                                href="https://github.com/ac209-project/ac209-project/blob/master/w2v/word2vec_paper.pdf"
                                target="_blank">(Mikolov, Chen, Corrado, & Dean, 2013)</a>
                        </li>
                        <li>This project's <a href="https://github.com/ac209-project/ac209-project" target="_blank">GitHub
                            repository</a>.
                        </li>
                        <li>Course project guidlines <a href="https://github.com/cs109/a-2017/tree/master/Projects"
                                                        target="_blank">GitHub
                            repository</a></li>
                        <li>Website framework provided by <a
                                href="https://github.com/BlackrockDigital/startbootstrap-simple-sidebar"
                                target="_blank">BlackrockDigital</a>.
                        </li>
                    </ul>
                    </p>
                </div>
            </div>
            <hr>

            <div id="contact" class="row">
                <div class="col col-md-12"><h2>Contact</h2></div>
            </div>
            <div class="row">
                <div class="col col-md-9">
                    <p>This project was produced by the following students:</p>
                    <ul>
                        <li><a href="mailto:pblankley@g.harvard.edu">Paul Blankley</a></li>
                        <li><a href="mailto:ryanjanssen@g.harvard.edu">Ryan Janssen</a></li>
                        <li><a href="mailto:andrewlund@g.harvard.edu">Andrew Lund</a></li>
                        <li><a href="mailto:nathaniel_stein@g.harvard.edu">Nate Stein</a></li>
                    </ul>
                </div>
            </div>
        </div>
    </div>
</div>

<!-- Bootstrap core JavaScript -->
<script src="vendor/jquery/jquery.min.js"></script>
<script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

<!-- Menu Toggle Script -->
<script>
    $("#menu-toggle").click(function (e) {
//        e.preventDefault();
        $("#wrapper").toggleClass("toggled");
    });
</script>
</body>
</html>


<!--Table for possible use in results section-->
<!--<table class="table table-project">-->
<!--<thead>-->
<!--<tr>-->
<!--<th>Results without Word2vec</th>-->
<!--<th>Results with Word2vec</th>-->
<!--</tr>-->
<!--</thead>-->
<!--<tbody>-->
<!--<tr>-->
<!--<td>-->
<!--<table class="table table-striped">-->
<!--<thead>-->
<!--<th>Model</th>-->
<!--<th>Cross-validated validation<br>set R^2 mean & std<br>(5-folds)</th>-->
<!--<th>Train Score</th>-->
<!--<th>Test Score</th>-->
<!--</thead>-->
<!--<tbody>-->
<!--<tr>-->
<!--<td>Linear Regression</td>-->
<!--<td>-9.661837490455958e+20, 1.3658652789203555e+21</td>-->
<!--<td>0.132484290729</td>-->
<!--<td>-7.77393283572e+18</td>-->
<!--</tr>-->
<!--<tr>-->
<!--<td>Ridge Regression</td>-->
<!--<td>-0.030256576859918376, 0.11125313901459834</td>-->
<!--<td>0.0853779911556</td>-->
<!--<td>0.0413614492559</td>-->
<!--</tr>-->
<!--<tr>-->
<!--<td>Lasso Regression</td>-->
<!--<td>-0.030256576859918376, 0.11125313901459834</td>-->
<!--<td>0.0853779911556</td>-->
<!--<td>0.0413614492559</td>-->
<!--</tr>-->
<!--<tr>-->
<!--<td>Elastic Net Regression</td>-->
<!--<td>-0.0028011693799219937, 0.06249175213203975</td>-->
<!--<td>0.0884215423941</td>-->
<!--<td>0.0410473844718</td>-->
<!--</tr>-->
<!--<tr>-->
<!--<td>k-NN Regression</td>-->
<!--<td>0.013480236420100952, 0.014509798407915084</td>-->
<!--<td>0.0923044971552</td>-->
<!--<td>0.0447576215128</td>-->
<!--</tr>-->
<!--<tr>-->
<!--<td>Random Forest Regression</td>-->
<!--<td>0.06498151001454726, 0.03988285917502669</td>-->
<!--<td>0.878798558284</td>-->
<!--<td>0.102835631709</td>-->
<!--</tr>-->
<!--<tr>-->
<!--<td>AdaBoost Regression</td>-->
<!--<td>-0.06615510226947337, 0.14867997551870718</td>-->
<!--<td>0.471762846853</td>-->
<!--<td>0.0671178069851</td>-->
<!--</tr>-->
<!--<tr>-->
<!--<td>XGBoost Regression</td>-->
<!--<td>-0.06309052342991424, 0.25255449612691144</td>-->
<!--<td>0.471512394636</td>-->
<!--<td>0.110631159802</td>-->
<!--</tr>-->
<!--<tr>-->
<!--<td>SVM Regression</td>-->
<!--<td>0.050170049519681514, 0.014360689088760155</td>-->
<!--<td>0.161309635032</td>-->
<!--<td>0.0632341098191</td>-->
<!--</tr>-->
<!--</tbody>-->
<!--</table>-->
<!--</td>-->
<!--<td>-->
<!--<table class="table table-striped">-->
<!--<thead>-->
<!--<th>Model</th>-->
<!--<th>Cross-validated validation<br>set R^2 mean & std<br>(5-folds)</th>-->
<!--<th>Train Score</th>-->
<!--<th>Test Score</th>-->
<!--</thead>-->
<!--<tbody>-->
<!--<tr>-->
<!--<td>Linear Regression</td>-->
<!--<td>0</td>-->
<!--<td>0</td>-->
<!--<td>0</td>-->
<!--</tr>-->
<!--<tr>-->
<!--<td>Ridge Regression</td>-->
<!--<td>0</td>-->
<!--<td>0</td>-->
<!--<td>0</td>-->
<!--</tr>-->
<!--<tr>-->
<!--<td>Lasso Regression</td>-->
<!--<td>0</td>-->
<!--<td>0</td>-->
<!--<td>0</td>-->
<!--</tr>-->
<!--<tr>-->
<!--<td>Elastic Net Regression</td>-->
<!--<td>0</td>-->
<!--<td>0</td>-->
<!--<td>0</td>-->
<!--</tr>-->
<!--<tr>-->
<!--<td>k-NN Regression</td>-->
<!--<td>0</td>-->
<!--<td>0</td>-->
<!--<td>0</td>-->
<!--</tr>-->
<!--<tr>-->
<!--<td>Random Forest Regression</td>-->
<!--<td>0</td>-->
<!--<td>0</td>-->
<!--<td>0</td>-->
<!--</tr>-->
<!--<tr>-->
<!--<td>AdaBoost Regression</td>-->
<!--<td>0</td>-->
<!--<td>0</td>-->
<!--<td>0</td>-->
<!--</tr>-->
<!--<tr>-->
<!--<td>SVM Regression</td>-->
<!--<td>0</td>-->
<!--<td>0</td>-->
<!--<td>0</td>-->
<!--</tr>-->
<!--</tbody>-->
<!--</table>-->
<!--</td>-->
<!--</tr>-->
<!--</tbody>-->
<!--</table>-->
